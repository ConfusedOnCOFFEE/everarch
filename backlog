* how do we report claims found in attr query?
there should be at least these response modes:
** report only ref
** report ref and some attributes specified by key
** report ref and all attributes
* evr-attr-index should listen on a socket for querries
* introduce evr-attr-cli cmd with index query feature
command line client which sends querries to a evr-attr-index and lists
found blobs.
* implement offset and limit in attr queries
tag=todo offset=0 limit=100
* implement t in attr queries
tag=todo t=12345
tag=todo t=1970-01-01T00:00:07Z
* add ref key to attr query language to match ref
introduce ref as keyword to match the ref of a claim. later "ref" (in
double quotes) should mean the attribute with the key ref.
* add boolean or operator to attr query language
#+BEGIN_SRC
(tag=todo || tag=backlog) && tag=howto
#+END_SRC
* add braces to attr query language
#+BEGIN_SRC
(tag=todo || tag=backlog) && tag=howto
#+END_SRC
* add not operator to attr query language
#+BEGIN_SRC
!tag=nsfw
#+END_SRC
* allow attr query args in quotes
#+BEGIN_SRC
'the key'='the value'
"the key"="the value"
#+END_SRC
* add match functions to attr query language
#+BEGIN_SRC
tag=todo && is_image(mime_type)
#+END_SRC
* make boolean and operator '&&' optional in attr query language
#+BEGIN_SRC
(tag=todo || tag=backlog) tag=howto
#+END_SRC
* introduce content sourced attritutes
attr specs should contain declarations for content sourced
attributes. content sourced attributes are scripts which are executed
with every claim and can produce an attr claim as output.

the attr spec for content based attributes might look like this:

#+BEGIN_SRC xml
<attr-spec>
  <attr-def k="tag" type="str"/>
  <stylesheet blob="sha3-224-00000000000000000000000000000000000000000000000000000000"/>
  <attr-factory blob="sha3-224-00000000000000000000000000000000000000000000000000000001"/>
</attr-spec>
#+END_SRC

the attr-factory must point to an executable. for example an elf
binary, shell or python script.
* store flags and blob size redundant in buckets
right now flags and blob size in the evr-glacier-storage are storend
once for every blob and without any checksum.

there should be either a checksum for the two fields or it should be
stored redundant. this should reduce the risk of breaking a whole
bucket if one blob in it has a bit error.
* gracefully handle sqlite database is locked in evr-glacier-storage
sqlite's step function will exit with SQLITE_LOCKED if a table is
locked for more than 1sec (configured right now).

a SQLITE_LOCKED error should be indicated as 'resource temporary not
available' to the client.
* gracefully handle sqlite database is locked in evr-attr-index
sqlite's step function will exit with SQLITE_LOCKED if a table is
locked for more than 1sec (configured right now).

a SQLITE_LOCKED error should be indicated as 'resource temporary not
available' to the client.
* add setup hints to README
** gpg signing key
hint the user that the default gpg signing key is used for signing
claims. don't lose it and be aware of etc.
** config file locations
indicate where config files should be placed and how they should look
* replace struct chunk_set with linked list
dny-mem.h should provide one growable random access data structure and
one growable linked list data structure.

especially struct dynamic_array is not very well fitted for growing
because of the evr_chunk_set_max_chunks limitation.

struct dynamic_array should be renamed to hint the random access
usage. maybe rabuf instead of dynamic_array and llbuf for chunk_set.
* use writev instead of buf copying
writev can write mutliple buffers in one system call. this may reduce
the amout of memory being copied before a write call. there are
probably some places in glacier.c and the networking code which can
benefit from writev.
* replace own queues with lib io_uring
inter thread communitcation queues have been implemented in struct
evr_work_watch_ctx and struct evr_persister_ctx.

for the sake of using well tested code we should check migrating our
own queues to lib io_uring. mentioned by pitrp.
* implement an evr-glacier-storage blob put/get benchmark
should connect via network socket. send lots of blobs. request lots of
blobs. count blobs per second. maybe different blob sizes etc.
* add option for flags to evr-glacier-cli put command
right now flags=0 is always sent when putting a blob to the storage.

the put flags should be specifyable using command line arguments in
the evr-glacier-cli tool.
* align chunk size with RLIMIT_FSIZE
see [[elisp:(manual-entry "setrlimit(2)")][setrlimit(2)]] for retrieving RLIMIT_FSIZE and limit the chunk size
regarding to it. also the chunk size should not grow over 1MB.
* create bucket directory if not existing :bdircre:
* repair out of sync bucket end pointer and file end offset :beprep:
the whole bucket should be scanned with validation of each key and
blob. if the file probably ends with one corrupt blob it should be
discarded.

it's important to be sensible about the discarded data at the end of
the file. maybe there should be an 'autorepair' flag in the
configuration.
