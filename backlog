* implement an integration test / benchmark
should connect via network socket. send lots of blobs. request lots of
blobs. count blobs per second. maybe different blob sizes etc.
* move glacier storage client functions into glacier-client.[hc]
right now the evr-glacier-cli.c contains functions for handling blob
put and blob get commands. code should be centralized in
glacier-client.[ch] in order to be reused in other future clients like
the file upload service.
* implement blob signing
struct chunk_set data should be signable using a pgp key.
* implement claim parse and format functions
claims should be encoded in XML. this provides the benefit that xml
namespaces for claim types can be used. also xml is a format here to
stay forever. so blobs containing xml should easily be parseable also
in the future.

a file claim might look like the following when pretty printed

#+BEGIN_SRC xml
<?xml version="1.0" encoding="UTF-8"?>
<claim-set
  xmlns="https://ma300k.de/everarch/claims/"
  created="Fri, 04 Feb 2022 18:26:13 +0000">
    <file name="some-file.txt">
        <body>
            <segment ref="sha3-224-…"/>
            <segment ref="sha3-224-…"/>
            …
        </body>
    </file>
    <my-custom-claim xmlns="https://example.org/">
        …
    </my-custom-claim>
</claim-set>
#+END_SRC

which date format should be used for the created timestamp? xml schema
defines a [[http://www.datypic.com/sc/xsd/t-xsd_dateTime.html][dateTime]] datatype which supports dates like
"2004-04-12T13:20:00Z".

on the other hard we could use use email's date format RFC 5322 like
"Fri, 04 Feb 2022 18:26:13 +0000".

also possible would be ISO 8601 format with seconds precision like
"2022-02-04T19:45:13+00:00".
* implement a evr-file-storage service
should provide put and get endpoints for files.
* add option for flags to evr-glacier-cli put command
right now flags=0 is always sent when putting a blob to the storage.

the put flags should be specifyable using command line arguments in
the evr-glacier-cli tool.
* align chunk size with RLIMIT_FSIZE
see [[elisp:(manual-entry "setrlimit(2)")][setrlimit(2)]] for retrieving RLIMIT_FSIZE and limit the chunk size
regarding to it. also the chunk size should not grow over 1MB.
* create bucket directory if not existing :bdircre:
* repair out of sync bucket end pointer and file end offset :beprep:
the whole bucket should be scanned with validation of each key and
blob. if the file probably ends with one corrupt blob it should be
discarded.

it's important to be sensible about the discarded data at the end of
the file. maybe there should be an 'autorepair' flag in the
configuration.
